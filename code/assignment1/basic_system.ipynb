{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic System\n",
    "\n",
    "This notebook provides code for implementing a very simple machine learning system for named entity recognition.\n",
    "It uses logistic regression and one feature (the token itself).\n",
    "Links to information about the packages are provided. Your job is to document the code and use it to train a system. You can then use your evaluation code to provide the first basic evaluation of your system.\n",
    "In the next assignment, you can use this as a basis to experiment with more features and more machine learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# If you want to include other modules, you can add them here\n",
    "# Please note the recommendations on using modules in the Programming General Guidelines\n",
    "\n",
    "#recommended resource for examples:\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_labels(trainingfile):\n",
    "    \n",
    "    data = []\n",
    "    targets = []\n",
    "    with open(trainingfile, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) > 0:\n",
    "                token = components[0]\n",
    "                feature_dict = {'token':token}\n",
    "                data.append(feature_dict)\n",
    "                #gold is in the last column\n",
    "                targets.append(components[-1])\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(inputfile):\n",
    "   \n",
    "    data = []\n",
    "    with open(inputfile, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) > 0:\n",
    "                token = components[0]\n",
    "                feature_dict = {'token':token}\n",
    "                data.append(feature_dict)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(train_features, train_targets):\n",
    "   \n",
    "    logreg = LogisticRegression()\n",
    "    vec = DictVectorizer()\n",
    "    features_vectorized = vec.fit_transform(train_features)\n",
    "    model = logreg.fit(features_vectorized, train_targets)\n",
    "    \n",
    "    return model, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(model, vec, inputdata, outputfile):\n",
    "  \n",
    "    features = extract_features(inputdata)\n",
    "    features = vec.transform(features)\n",
    "    predictions = model.predict(features)\n",
    "    outfile = open(outputfile, 'w')\n",
    "    counter = 0\n",
    "    for line in open(inputdata, 'r'):\n",
    "        if len(line.rstrip('\\n').split()) > 0:\n",
    "            outfile.write(line.rstrip('\\n') + '\\t' + predictions[counter] + '\\n')\n",
    "            counter += 1\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    \n",
    "    #a very basic way for picking up commandline arguments\n",
    "    if argv is None:\n",
    "        argv = sys.argv\n",
    "        \n",
    "    #Note 1: argv[0] is the name of the python program if you run your program as: python program1.py arg1 arg2 arg3\n",
    "    #Note 2: sys.argv is simple, but gets messy if you need it for anything else than basic scenarios with few arguments\n",
    "    #you'll want to move to something better. e.g. argparse (easy to find online)\n",
    "    \n",
    "    \n",
    "    #you can replace the values for these with paths to the appropriate files for now, e.g. by specifying values in argv\n",
    "    #argv = ['mypython_program','','','']\n",
    "    trainingfile = argv[1]\n",
    "    inputfile = argv[2]\n",
    "    outputfile = argv[3]\n",
    "    \n",
    "    training_features, gold_labels = extract_features_and_labels(trainingfile)\n",
    "    ml_model, vec = create_classifier(training_features, gold_labels)\n",
    "    classify_data(ml_model, vec, inputfile, outputfile)\n",
    "\n",
    "# uncomment this when using this in a script    \n",
    "    \n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember that the first element of the list is not used \n",
    "# (since this is the `python command when the args are read from sys.argv)\n",
    "# make sure to complete the rest of the list correctly\n",
    "args = ['python', '../../data/reuters-train-tab-stripped.en', '../../data/gold_stripped.conll', '../../data/out.txt']\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}